{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d471bfb0",
   "metadata": {},
   "source": [
    "## Data Preprocessing Module Design\n",
    "\n",
    "- Module name: `preprocess_data`\n",
    "- Exposed functions:\n",
    "  - Get the formatted raw dataset\n",
    "  - Get filtered dataset\n",
    "  - Get tokenized dataset\n",
    "  - Get dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b4e685",
   "metadata": {},
   "source": [
    "### Raw Dataset\n",
    "\n",
    "- For summaries in the same post, concatenate those with same emotion labels\n",
    "- Argument: Data split\n",
    "- Return: Formatted raw dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5b14f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def get_raw_dataset(split, concat_same_emo=True):\n",
    "    '''\n",
    "    Raw dataset format:\n",
    "    raw_dataset: [sample]\n",
    "    sample     : { 'post': str, 'annos': [anno] }\n",
    "    anno       : { 'emo': str, 'summ': str }\n",
    "    '''\n",
    "    data_dir = Path('data/train_val_test-WITH_POSTS')\n",
    "    assert data_dir.exists(), 'Data not in the correct file path.'\n",
    "\n",
    "    data_path = data_dir / f'{split}_anonymized-WITH_POSTS.json'\n",
    "    assert data_path.exists(), f'Cannot find {split} data split at {data_path}.'\n",
    "\n",
    "    with data_path.open() as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    raw_dataset = []\n",
    "\n",
    "    if concat_same_emo:\n",
    "        for raw_sample in json_data.values():\n",
    "            emo2summ = defaultdict(str)\n",
    "            for anno in chain(*raw_sample['Annotations'].values()):\n",
    "                if anno['Emotion'] != 'NA':\n",
    "                    emo2summ[anno['Emotion']] += ' ' + anno['Abstractive']\n",
    "\n",
    "            sample = {'post': raw_sample['Reddit Post'], 'annos': []}\n",
    "            for emo, summ in emo2summ.items():\n",
    "                anno = {'emo': emo, 'summ': summ}\n",
    "                sample['annos'].append(anno)\n",
    "            raw_dataset.append(sample)\n",
    "    else:\n",
    "        for raw_sample in json_data.values():\n",
    "            sample = {'post': raw_sample['Reddit Post'], 'annos': []}\n",
    "            for anno in chain(*raw_sample['Annotations'].values()):\n",
    "                if anno['Emotion'] != 'NA':\n",
    "                    emo_summ = {'emo': anno['Emotion'], 'summ': anno['Abstractive']}\n",
    "                    sample['annos'].append(emo_summ)\n",
    "            raw_dataset.append(sample)\n",
    "\n",
    "    return raw_dataset\n",
    "\n",
    "\n",
    "def verify_raw_dataset(raw_ds):\n",
    "    assert type(raw_ds) == list\n",
    "    for sample in raw_ds:\n",
    "        assert (ks := list(sample.keys())) == ['post', 'annos'], f'Invalid key set {ks}'\n",
    "        assert len(sample['annos']) > 0, 'Empty emotion summary annotation'\n",
    "        for anno in sample['annos']:\n",
    "            assert (ks := list(anno.keys())) == ['emo', 'summ'], f'Invalid key set {ks}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3bf1e566",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emo': 'fear', 'summ': \" I don't think am safe around my bosses, because one is vaccinated and isn't. I am really confuse on what to do. I'm apprehensive about whether I should be going into work still when one of my unvaccinated bosses was exposed to COVID last week through his uncle, who has tested positive.\"}\n",
      "\n",
      "{'emo': 'fear', 'summ': \"I don't think am safe around my bosses, because one is vaccinated and isn't. I am really confuse on what to do.\"}\n",
      "{'emo': 'fear', 'summ': \"I'm apprehensive about whether I should be going into work still when one of my unvaccinated bosses was exposed to COVID last week through his uncle, who has tested positive.\"}\n"
     ]
    }
   ],
   "source": [
    "raw_train_ds = get_raw_dataset('train')\n",
    "raw_train_ds2 = get_raw_dataset('train', False)\n",
    "print(*raw_train_ds[3]['annos'], sep='\\n')\n",
    "print('')\n",
    "print(*raw_train_ds2[3]['annos'], sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cf062438",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': \"In my area we have a super high vaccination rate. In the sf Metro area we have 65 fully vaccinated, and some parts of it like sf have 68.9 fully vaccinated of whole population. And yet the delta is still surging here. The cdc just said in areas with high transmission masks should be mandated again and I feel completely hopeless. It's so far unknown if the bay area will reimplement masks but I'm sure they will. It's been close too 2 weeks since LA reinstated masks and the cases are still exploding there which is pretty hopeless. I can just see another lockdown coming maybe in the winter.\",\n",
       " 'annos': [{'emo': 'anticipation',\n",
       "   'summ': 'The person is anticipating a new lockdown, realizing that changes will occur and is on alert with COVID-19.'},\n",
       "  {'emo': 'fear',\n",
       "   'summ': 'The person cannot relax and becomes worried and apprehensive about the increase in the number of COVID-19 cases.'},\n",
       "  {'emo': 'sadness',\n",
       "   'summ': 'The person feels defeated and without expectations of having to bear wearing masks again.'},\n",
       "  {'emo': 'anticipation',\n",
       "   'summ': 'There have been limited vaccination in the delta but am sure it will improve.'}]}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_val_ds = get_raw_dataset('val')\n",
    "raw_val_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bd559961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'emo': 'anticipation', 'summ': 'The person is anticipating a new lockdown, realizing that changes will occur and is on alert with COVID-19.'}\n",
      "{'emo': 'fear', 'summ': 'The person cannot relax and becomes worried and apprehensive about the increase in the number of COVID-19 cases.'}\n",
      "{'emo': 'sadness', 'summ': 'The person feels defeated and without expectations of having to bear wearing masks again.'}\n",
      "{'emo': 'anticipation', 'summ': 'There have been limited vaccination in the delta but am sure it will improve.'}\n"
     ]
    }
   ],
   "source": [
    "for sample in raw_val_ds:\n",
    "    emos = [anno['emo'] for anno in sample['annos']]\n",
    "    if len(emos) != len(set(emos)):\n",
    "        print(*sample['annos'], sep='\\n')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8ff11ae3",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'post': \"Hey guys, Apologies- pessimistic post incoming- feel free to delete if inappropriate. I'm struggling so much at the moment with having any sort of hope for the future. It just feels like we will never get normality back. COVID has completely ruined me. I went from being a (mostly) happy and functional human to depressed and suicidal since 2020. I take anti depressants now and I started therapy but even on my good days, I still feel like there's this dark cloud over my head and I'm waiting for the next shitstorm. I live in the UK and we've had three long lockdowns. Everything was looking pretty hopeful a few months ago, but since the last lockdown rules started easing, cases and hospitalisations have started rising again, even though we're doing pretty well with vaccinations. Our Government have handled the pandemic pretty poorly throughout and managed to let the Delta variant in with their loose border control measures. It just feels like this never ending cycle of rising cases, lockdown, falling cases, lift lockdown, rising cases again, etc etc and I'm terrified of going into another lockdown in the Autumn. I can't do it again. We keep saying the lockdowns are to protect our (underfunded) NHS from being overwhelmed but if hospitalisations are already getting too high now in the SUMMER, how the hell will they cope with a Winter wave with not only COVID cases but also a new wave of Flu cases which have been low the last year because of the lockdowns??? I feel guilty for complaining as I know other people have it much worse, and having already had the virus, it's not affected me all that badly. But the restrictions have meant I can no longer do my job (musician), I can't meet a partner, I've lost all hope for the future and I just feel like I'm waiting for the next bit of bad news. If the vaccines aren't enough for getting us out of this shit, what will be???? I just don't feel like life is worth living anymore under these restrictions. Sorry for being negative, I just needed to rant.\",\n",
       " 'annos': [{'emo': 'anger',\n",
       "   'summ': \"I'm frustrated with our government and how they didn't do enough to protect us from COVID, and now we're living through the consequences of their poor decisions.\"},\n",
       "  {'emo': 'anticipation',\n",
       "   'summ': \"I expect that COVID cases are going to get much worse in  winter and we'll have to go back to lockdown. \"},\n",
       "  {'emo': 'fear',\n",
       "   'summ': \"I worry that if things are bad now they will be much worse in Winter, and I'm afraid we'll have to go into another lockdown.  \"},\n",
       "  {'emo': 'sadness',\n",
       "   'summ': 'Every time things seem to get better they then get worse, and we get stuck in another lockdown, and being in lockdown makes me feel like I have no life or future to look forward to and I just feel hopeless. '},\n",
       "  {'emo': 'anger',\n",
       "   'summ': \"I'm angry at my government's awful protocols managing to introduce Delta into the country.\"},\n",
       "  {'emo': 'fear',\n",
       "   'summ': \"I'm afraid of another lockdown happening because I could barely handle the last one. In addition, I'm worried about our hospital system handling the wave in the Winter.\"},\n",
       "  {'emo': 'sadness',\n",
       "   'summ': \"I feel incredibly defeated right now. The pandemic has made me a sadder person. The situation in the UK has been going downhill. I feel bad about complaining about my situation because it isn't that bad compared to some others. The pandemic has taken away my ability to work.\"}]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_test_ds = get_raw_dataset('test')\n",
    "raw_test_ds[85]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdc1ef4",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "- Sampled from raw dataset\n",
    "- Formatted as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d09db53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data_dict(dd):\n",
    "    key_set = ['post', 'emo', 'summ']\n",
    "    assert list(dd.keys()) == key_set, f'Invalid key set: {dd.keys()}'\n",
    "\n",
    "    len_dict = {k: len(dd[k]) for k in key_set}\n",
    "    assert len_dict['post'] == len_dict['emo'] == len_dict['summ'], f'{len_dict=}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ae58a",
   "metadata": {},
   "source": [
    "#### All summaries\n",
    "\n",
    "- Duplicate posts to match each of its summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f3a48fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_all_summaries(raw_dataset):\n",
    "    verify_raw_dataset(raw_dataset)\n",
    "    data_dict = {'post': [], 'emo': [], 'summ': []}\n",
    "\n",
    "    for sample in raw_dataset:\n",
    "        for anno in sample['annos']:\n",
    "            data_dict['post'].append(sample['post'])\n",
    "            data_dict['emo'].append(anno['emo'])\n",
    "            data_dict['summ'].append(anno['summ'])\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def data_dict_allsumm(split, **kwargs):\n",
    "    raw_ds = get_raw_dataset(split, **kwargs)\n",
    "    sampled_raw_ds = sample_all_summaries(raw_ds)\n",
    "    return sampled_raw_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "9d85aab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'sadness': 360,\n",
       "         'anger': 470,\n",
       "         'fear': 765,\n",
       "         'trust': 99,\n",
       "         'anticipation': 873,\n",
       "         'disgust': 192,\n",
       "         'joy': 134})"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_ds = data_dict_allsumm('train')\n",
    "Counter(train_ds['emo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d782dfc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'anticipation': 206,\n",
       "         'fear': 192,\n",
       "         'sadness': 97,\n",
       "         'joy': 32,\n",
       "         'anger': 114,\n",
       "         'trust': 23,\n",
       "         'disgust': 41})"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "train_ds = data_dict_allsumm('val')\n",
    "Counter(train_ds['emo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c804ab80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = data_dict_allsumm('train')\n",
    "train_ds['post'][0] == train_ds['post'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf9eca9",
   "metadata": {},
   "source": [
    "#### Balanced\n",
    "\n",
    "- Each emotion has the same number of summaries\n",
    "- Specified number of samples per emotion\n",
    "- No duplicated posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "94e6de97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "EMO_LIST = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'trust', 'anticipation']\n",
    "\n",
    "\n",
    "def data_dict_balanced(split, sample_size=float('inf')):\n",
    "    raw_dataset = get_raw_dataset(split, concat_same_emo=True)\n",
    "    data_dict = {'post': [], 'emo': [], 'summ': []}\n",
    "\n",
    "    n_samples = dict.fromkeys(EMO_LIST, 0)\n",
    "    sampling_emos = set(EMO_LIST)\n",
    "    emo_freq = Counter(sample_all_summaries(raw_dataset)['emo'])\n",
    "    sample_size = min(min(emo_freq.values()), sample_size)\n",
    "\n",
    "    for sample in raw_dataset:\n",
    "        annos = list(filter(lambda es: es['emo'] in sampling_emos, sample['annos']))\n",
    "        if annos:\n",
    "            anno = min(annos, key=lambda anno: emo_freq[anno['emo']])\n",
    "            data_dict['post'].append(sample['post'])\n",
    "            data_dict['emo'].append(anno['emo'])\n",
    "            data_dict['summ'].append(anno['summ'])\n",
    "\n",
    "            emo = anno['emo']\n",
    "            n_samples[emo] += 1\n",
    "            if n_samples[emo] == sample_size:\n",
    "                sampling_emos.remove(emo)\n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fc531203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'trust': 99,\n",
       "          'sadness': 99,\n",
       "          'fear': 99,\n",
       "          'anger': 99,\n",
       "          'disgust': 99,\n",
       "          'joy': 99,\n",
       "          'anticipation': 99}),\n",
       " True)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_ds = data_dict_balanced('train')\n",
    "Counter(train_ds['emo']), len(set(train_ds['post'])) == len(train_ds['post'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c04fdeed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'sadness': 10,\n",
       "          'anticipation': 10,\n",
       "          'joy': 10,\n",
       "          'anger': 10,\n",
       "          'trust': 10,\n",
       "          'fear': 10,\n",
       "          'disgust': 10}),\n",
       " True)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ds = data_dict_balanced('val', sample_size=10)\n",
    "Counter(val_ds['emo']), len(set(val_ds['post'])) == len(val_ds['post'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3e2d25",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "- Configure dataset:\n",
    "  - Argument: tokenizer\n",
    "  - Return: Build dataset function\n",
    "- Build dataset function:\n",
    "  - Argument: data dictionary\n",
    "  - Return: dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "fe268196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def config_dataset(tokenizer):\n",
    "    instr = 'Generate a summary of what triggered {} in this post: {}'\n",
    "\n",
    "    def make_prompt(sample):\n",
    "        return {'prompt': instr.format(sample['emo'], sample['post'])}\n",
    "\n",
    "    def tokenize(sample):\n",
    "        inputs = tokenizer(\n",
    "            sample['prompt'],\n",
    "            max_length=512, truncation=True, padding='max_length'\n",
    "        )\n",
    "        labels = tokenizer(\n",
    "            sample['summ'], return_attention_mask=False,\n",
    "            max_length=128, truncation=True, padding='max_length'\n",
    "        )\n",
    "        return {**inputs, 'labels': labels['input_ids']}\n",
    "\n",
    "    def make_dataset(data_dict):\n",
    "        verify_data_dict(data_dict)\n",
    "        dataset = Dataset.from_dict(data_dict)\n",
    "        dataset = dataset.map(make_prompt)\n",
    "        dataset = dataset.remove_columns(['post', 'emo'])\n",
    "        dataset = dataset.map(tokenize, batched=True)\n",
    "        dataset = dataset.remove_columns(['prompt', 'summ'])\n",
    "        dataset.set_format('torch')\n",
    "        return dataset\n",
    "\n",
    "    return make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5d0a5aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/693 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/693 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 693\n",
       "})"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\n",
    "data_dict = data_dict_balanced('train')\n",
    "make_dataset = config_dataset(tokenizer)\n",
    "dataset = make_dataset(data_dict)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3569ae4a",
   "metadata": {},
   "source": [
    "### Dataloader\n",
    "\n",
    "- Configure dataloader:\n",
    "  - Arguments: model, tokenizer, dataloader kwargs\n",
    "  - Return: build dataloader function\n",
    "- Build dataloader function:\n",
    "  - Argument: dataset\n",
    "  - Return: dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "ee68e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import sched_getaffinity\n",
    "import torch\n",
    "from absl import flags\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def config_dataloader(model, tokenizer, **kwargs):\n",
    "    collator = DataCollatorForSeq2Seq(tokenizer, model, padding='longest')\n",
    "\n",
    "    def seed_worker(worker_id):\n",
    "        worker_seed = torch.initial_seed() % 2**32\n",
    "        np.random.seed(worker_seed)\n",
    "        random.seed(worker_seed)\n",
    "\n",
    "    dl_kwargs = dict(\n",
    "        collate_fn=collator, batch_size=FLAGS.batch_size,\n",
    "        num_workers=len(sched_getaffinity(0)), worker_init_fn=seed_worker\n",
    "    )\n",
    "    dl_kwargs.update(kwargs)\n",
    "\n",
    "    make_dataloader = lambda dataset: DataLoader(dataset, **dl_kwargs)\n",
    "\n",
    "    return make_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "0cf52f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained('facebook/bart-base')\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-base')\n",
    "make_dataloader = config_dataloader(model, tokenizer, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8b694b",
   "metadata": {},
   "source": [
    "## Training Script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e4b696",
   "metadata": {},
   "source": [
    "### Create Argument Flags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dc743c",
   "metadata": {},
   "source": [
    "### Create Components\n",
    "\n",
    "- Model\n",
    "  - Argument: `checkpoint`\n",
    "- Tokenizer\n",
    "  - Argument: `checkpoint`\n",
    "  - if checkpoint is T5: `model_max_length=512`\n",
    "- Optimizer\n",
    "  - Arguments:\n",
    "    - model parameters\n",
    "    - `learning rate`\n",
    "- Scheduler\n",
    "  - Arguments:\n",
    "    - optimizer\n",
    "    - warmup schedule if `warmup` is defined else constant schedule\n",
    "- Writer\n",
    "  - Argument: `experiment name`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2a071",
   "metadata": {},
   "source": [
    "### Training Pipeline\n",
    "\n",
    "- Setup model and optimizer\n",
    "- Setup progress bar and logging config\n",
    "- Initialize `best_rouge` and `accum_loss`\n",
    "\n",
    "For each batch in train dataloader at forward step `step`:\n",
    "\n",
    "- Forward and backward pass:\n",
    "    - Forward pass to get loss\n",
    "    - Average loss by gradient accumulation steps `grad_acc`\n",
    "    - Backward pass\n",
    "    - Accumulate loss\n",
    "- Optimize model every `grad_acc` (gradient accumulation) forward steps:\n",
    "  - Make a step optimizer and scheduler\n",
    "  - Update progress bar\n",
    "- Log metrics every `eval_freq` optimization steps:\n",
    "  - Log learning rate\n",
    "  - Log average loss with accumulates loss, reset `accum_loss`\n",
    "  - Evaluate on train data subset, log ROUGE-L score, and print it with logging\n",
    "  - Evaluate on validation data subset, log ROUGE-L score, and print it with logging\n",
    "  - Reset model status to `train`\n",
    "  - if model improves upon `best_rouge`, update it and save the model\n",
    "\n",
    "- Close progress bar and writer objects\n",
    "- Save tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce6e14c",
   "metadata": {},
   "source": [
    "#### Evaluate Pipeline on Training Dataset\n",
    "\n",
    "For each bath in validation dataloader:\n",
    "- Generate summary on `torch.inference_mode()`\n",
    "- Log ROUGE score\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
